Import necessary libraries
import pandas as pd
import numpy as np


%matplotlib inline
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.neighbors import KNeighborsClassifier
from sklearn import tree

from sklearn.model_selection import train_test_split
from sklearn.compose import make_column_transformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import make_column_transformer
from sklearn.preprocessing import StandardScaler
from sklearn import metrics

from sklearn.decomposition import PCA
from google.colab import drive
drive.mount('/content/drive')
Loading the dataset
 data = pd.read_csv('/content/drive/MyDrive/diabetes1/heart/heart.csv')
data.head()

Statistical summary of the Dataset
data.describe().T

Data cleaning
data.info()
Shape of Dataset
data.shape
Check and Drop Duplicates if any
# Check for duplicates and drop them if they exist
if data.duplicated().any():
 print("Duplicate rows found!")
 data.drop_duplicates(inplace=True)
else:
 print("No Duplicate Rows found!")

Check for Missing Values
# Check for missing values
print(data.isnull().sum())

data.nunique()
The project has some attributes that have more than two unique values, we'll use OneHotEncoder in the preprocessing step later
data =  data[data.columns].replace({'Yes':1, 'No':0, 'Male':1,'Female':0,'No, borderline diabetes':'0','Yes (during pregnancy)':'1' })
data['Diabetic'] = data['Diabetic'].astype(int)

Data visualization
fig, ax = plt.subplots(figsize = (8,4))

ax.hist(data[data["HeartDisease"]==1]["Sex"], bins=15, alpha=0.5, color="yellow", label="HeartDisease")
ax.hist(data[data["HeartDisease"]==0]["Sex"], bins=15, alpha=0.5, color="lightblue", label="Normal")

ax.set_xlabel("Sex")
ax.set_ylabel("Frequency")

fig.suptitle("Distribution of heartdisease cases according to Sex")

ax.legend();

fig, ax = plt.subplots(figsize = (8,4))

ax.hist(data[data["HeartDisease"]==1]["Smoking"], bins=15, alpha=0.5, color="yellow", label="HeartDisease")
ax.hist(data[data["HeartDisease"]==0]["Smoking"], bins=15, alpha=0.5, color="lightblue", label="Normal")

ax.set_xlabel("Smoking")
ax.set_ylabel("Frequency")

fig.suptitle("Distribution of heartdisease cases according to being a smkoer or not.")

ax.legend();
fig, ax = plt.subplots(figsize = (8,4))

ax.hist(data[data["HeartDisease"]==1]["KidneyDisease"], bins=15, alpha=0.5, color="yellow", label="HeartDisease")
ax.hist(data[data["HeartDisease"]==0]["KidneyDisease"], bins=15, alpha=0.5, color="lightblue", label="Normal")

ax.set_xlabel("KidneyDisease")
ax.set_ylabel("Frequency")

fig.suptitle("Distribution of heartdisease cases according to kidneydisease")

ax.legend();

fig, ax = plt.subplots(figsize = (8,4))

ax.hist(data[data["HeartDisease"]==1]["SkinCancer"], bins=15, alpha=0.5, color="yellow", label="HeartDisease")
ax.hist(data[data["HeartDisease"]==0]["SkinCancer"], bins=15, alpha=0.5, color="lightblue", label="Normal")

ax.set_xlabel("SkinCancer")
ax.set_ylabel("Frequency")

fig.suptitle("Distribution  heartdisease cases based on previous exposure to skin cancer")

ax.legend();

fig, ax = plt.subplots(figsize = (8,4))

ax.hist(data[data["HeartDisease"]==1]["Stroke"], bins=15, alpha=0.5, color="yellow", label="HeartDisease")
ax.hist(data[data["HeartDisease"]==0]["Stroke"], bins=15, alpha=0.5, color="lightblue", label="Normal")

ax.set_xlabel("Stroke")
ax.set_ylabel("Frequency")

fig.suptitle("Distribution of hartdisease cases based on previous exposure to Stroke")

ax.legend();

fig, ax = plt.subplots(figsize = (8,4))

ax.hist(data[data["HeartDisease"]==1]["Diabetic"], bins=15, alpha=0.5, color="yellow", label="HeartDisease")
ax.hist(data[data["HeartDisease"]==0]["Diabetic"], bins=15, alpha=0.5, color="lightblue", label="Normal")

ax.set_xlabel("Diabetic")
ax.set_ylabel("Frequency")

fig.suptitle("Distribution hartdisease cases based on previous exposure to Diabetic")

ax.legend();

fig, ax = plt.subplots(figsize = (8,4))
sns.kdeplot(data[data["HeartDisease"]==1]["SleepTime"], alpha=0.5,shade = True, color="yellow", label="HeartDisease", ax = ax)
sns.kdeplot(data[data["HeartDisease"]==0]["SleepTime"], alpha=0.5,shade = True, color="lightblue", label="Normal", ax = ax)
plt.title('Distribution of SleepTime values', fontsize = 12)
ax.set_xlabel("SleepTime")
ax.set_ylabel("Frequency")
ax.legend();
plt.show()

fig, ax = plt.subplots(figsize = (8,4))
sns.kdeplot(data[data["HeartDisease"]==1]["PhysicalHealth"], alpha=0.5,shade = True, color="yellow", label="HeartDisease", ax = ax)
sns.kdeplot(data[data["HeartDisease"]==0]["PhysicalHealth"], alpha=0.5,shade = True, color="lightblue", label="Normal", ax = ax)
plt.title('Distribution of PhysicalHealth state for the last 30 days', fontsize = 12)
ax.set_xlabel("PhysicalHealth")
ax.set_ylabel("Frequency")
ax.legend();
plt.show()

fig, ax = plt.subplots(figsize = (8,4))
sns.kdeplot(data[data["HeartDisease"]==1]["MentalHealth"], alpha=0.5,shade = True, color="yellow", label="HeartDisease", ax = ax)
sns.kdeplot(data[data["HeartDisease"]==0]["MentalHealth"], alpha=0.5,shade = True, color="lightblue", label="Normal", ax = ax)
plt.title('Distribution of MenalHealth state for the last 30 days', fontsize = 12)
ax.set_xlabel("MentalHealth")
ax.set_ylabel("Frequency")
ax.legend();
plt.show()

Correlation Materix
correlation = data.corr().round(2)
plt.figure(figsize = (10,5))
sns.heatmap(correlation, annot = True, cmap = 'coolwarm')

Split Dataset for Training and Testing
#Select Features
features = data.drop(columns =['HeartDisease'], axis = 1)

#Select Target
target = data['HeartDisease']

# Set Training and Testing Data
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(features, target, shuffle = True, test_size = .2, random_state = 44)


print('Shape of training feature:', X_train.shape)
print('Shape of testing feature:', X_test.shape)
print('Shape of training label:', y_train.shape)
print('Shape of training label:', y_test.shape)

Data Preprocessing
Encoding
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder

# define the columns to be encoded
cols_to_encode = ['AgeCategory', 'Race', 'GenHealth']

# define the transformer
transformer = ColumnTransformer(transformers=[
    ('onehotencoder', OneHotEncoder(), cols_to_encode)
], remainder='passthrough')

Standardization
from sklearn.compose import make_column_transformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler

# Separate categorical and numeric features
categorical_features = ['AgeCategory', 'Race', 'GenHealth']
numeric_features = X_train.select_dtypes(include=[np.number]).columns.tolist()

# Define column transformer (this will apply the appropriate transformations to each column)
transformer = make_column_transformer(
    (OneHotEncoder(drop='first'), categorical_features),
    (StandardScaler(), numeric_features),
    remainder='passthrough'
)

# Fit and transform the training data
X_train = transformer.fit_transform(X_train)

# Transform the test data
X_test = transformer.transform(X_test)

Modeling
def evaluate_model(model, x_test, y_test):
    from sklearn import metrics

    # Predict Test Data
    y_pred = model.predict(x_test)

    # Calculate accuracy, precision, recall, f1-score, and kappa score
    acc = metrics.accuracy_score(y_test, y_pred)
    prec = metrics.precision_score(y_test, y_pred)
    rec = metrics.recall_score(y_test, y_pred)
    f1 = metrics.f1_score(y_test, y_pred)
    kappa = metrics.cohen_kappa_score(y_test, y_pred)

    # Calculate area under curve (AUC)
    y_pred_proba = model.predict_proba(x_test)[::,1]
    fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)
    auc = metrics.roc_auc_score(y_test, y_pred_proba)

    # Display confussion matrix
    cm = metrics.confusion_matrix(y_test, y_pred)

    return {'acc': acc, 'prec': prec, 'rec': rec, 'f1': f1, 'kappa': kappa,
            'fpr': fpr, 'tpr': tpr, 'auc': auc, 'cm': cm}

Building Mode
X_train

KNeighborsClassifier
# Building a model using KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors = 5)

knn.fit(X_train, y_train)


# Evaluate Model
knn_eval = evaluate_model(knn, X_test, y_test)

# Print result
print('Accuracy:', knn_eval['acc'])
print('Precision:', knn_eval['prec'])
print('Recall:', knn_eval['rec'])
print('F1 Score:', knn_eval['f1'])
print('Cohens Kappa Score:', knn_eval['kappa'])
print('Area Under Curve:', knn_eval['auc'])
print('Confusion Matrix:\n', knn_eval['cm'])

Decision Tree
# Building Decision Tree model
clf = tree.DecisionTreeClassifier(random_state=0)
clf.fit(X_train, y_train)

# Evaluate Model
clf_eval = evaluate_model(clf, X_test, y_test)

# Print result
print('Accuracy:', clf_eval['acc'])
print('Precision:', clf_eval['prec'])
print('Recall:', clf_eval['rec'])
print('F1 Score:', clf_eval['f1'])
print('Cohens Kappa Score:', clf_eval['kappa'])
print('Area Under Curve:', clf_eval['auc'])
print('Confusion Matrix:\n', clf_eval['cm'])# Evaluate Model

Result comparison
# Intitialize figure with two plots
fig, (ax1, ax2) = plt.subplots(1, 2)
fig.suptitle('Model Comparison', fontsize=14, fontweight='bold')
fig.set_figheight(4)
fig.set_figwidth(8)
fig.set_facecolor('white')

# First plot
## set bar size
barWidth = 0.2
clf_score = [clf_eval['acc'], clf_eval['prec'], clf_eval['rec'], clf_eval['f1'], clf_eval['kappa']]
knn_score = [knn_eval['acc'], knn_eval['prec'], knn_eval['rec'], knn_eval['f1'], knn_eval['kappa']]


## Set position of bar on X axis
r1 = np.arange(len(clf_score))
r2 = [x + barWidth for x in r1]

## Make the plot
ax1.bar(r1, clf_score, width=barWidth, edgecolor='white', label='Decision Tree')
ax1.bar(r2, knn_score, width=barWidth, edgecolor='white', label='K-Nearest Neighbors')

## Configure x and y axis
ax1.set_xlabel('Metrics', fontweight='bold')
labels = ['Accuracy', 'Precision', 'Recall', 'F1', 'Kappa']
ax1.set_xticks([r + (barWidth * 1.5) for r in range(len(clf_score))], )
ax1.set_xticklabels(labels)
ax1.set_ylabel('Score', fontweight='bold')
ax1.set_ylim(0, 1)

## Create legend & title
ax1.set_title('Evaluation Metrics', fontsize=14, fontweight='bold')
ax1.legend()

# Second plot
## Comparing ROC Curve
ax2.plot(clf_eval['fpr'], clf_eval['tpr'], label='Decision Tree, auc = {:0.5f}'.format(clf_eval['auc']))
ax2.plot(knn_eval['fpr'], knn_eval['tpr'], label='K-Nearest Nieghbor, auc = {:0.5f}'.format(knn_eval['auc']))

## Configure x and y axis
ax2.set_xlabel('False Positive Rate', fontweight='bold')
ax2.set_ylabel('True Positive Rate', fontweight='bold')

## Create legend & title
ax2.set_title('ROC Curve', fontsize=14, fontweight='bold')
ax2.legend(loc=4)

plt.show()
